{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**MOVIE RECOMMENDATION SYSTEM BASED ON CONCEPT OF DATA-CLUSTERING AND EIGEN VALUES PROBLEMS. [ USING KMEAN CLUSTERING AND SINGULAR VALUE DECOMPOSITION ]**\n"
      ],
      "metadata": {
        "id": "H-lViL_vHJfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Data Preparation\n",
        "\n",
        "Download and preprocess the MovieLens dataset.\n",
        "Create a user-item matrix with ratings."
      ],
      "metadata": {
        "id": "U2VESSK8IHOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Load data\n",
        "ratings = pd.read_csv('/content/ratings.csv')\n",
        "movies = pd.read_csv('/content/movies.csv')\n",
        "\n",
        "# Create a user-item matrix as a sparse CSR matrix\n",
        "user_item_matrix = ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "user_item_matrix = csr_matrix(user_item_matrix.values.astype(float))\n",
        "\n",
        "print(user_item_matrix)\n"
      ],
      "metadata": {
        "id": "-XCsf_1THJ3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea166057-7c82-404c-c2ba-a5fc158f3062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 292)\t5.0\n",
            "  (0, 302)\t3.5\n",
            "  (0, 303)\t5.0\n",
            "  (0, 653)\t5.0\n",
            "  (0, 874)\t3.5\n",
            "  (0, 1057)\t4.0\n",
            "  (0, 1142)\t3.5\n",
            "  (0, 1181)\t3.5\n",
            "  (0, 1200)\t5.0\n",
            "  (0, 1212)\t4.0\n",
            "  (0, 1222)\t3.5\n",
            "  (0, 1582)\t4.0\n",
            "  (0, 1900)\t2.5\n",
            "  (0, 1901)\t2.5\n",
            "  (0, 1957)\t2.5\n",
            "  (0, 2049)\t3.5\n",
            "  (0, 2232)\t4.5\n",
            "  (0, 2453)\t4.0\n",
            "  (0, 2511)\t5.0\n",
            "  (0, 2569)\t5.0\n",
            "  (0, 2719)\t4.5\n",
            "  (0, 3296)\t4.0\n",
            "  (0, 3409)\t5.0\n",
            "  (0, 3775)\t5.0\n",
            "  (0, 3964)\t5.0\n",
            "  :\t:\n",
            "  (15233, 17367)\t3.5\n",
            "  (15233, 17376)\t4.0\n",
            "  (15233, 17412)\t4.5\n",
            "  (15233, 17413)\t4.5\n",
            "  (15233, 17731)\t4.0\n",
            "  (15233, 17970)\t4.0\n",
            "  (15233, 18275)\t4.5\n",
            "  (15233, 18600)\t4.0\n",
            "  (15233, 18602)\t2.0\n",
            "  (15233, 19040)\t3.0\n",
            "  (15233, 19897)\t3.0\n",
            "  (15233, 20024)\t4.0\n",
            "  (15233, 20620)\t3.5\n",
            "  (15233, 20722)\t4.0\n",
            "  (15234, 35)\t5.0\n",
            "  (15234, 312)\t1.0\n",
            "  (15234, 474)\t4.0\n",
            "  (15234, 1016)\t4.0\n",
            "  (15234, 1057)\t5.0\n",
            "  (15234, 1066)\t4.0\n",
            "  (15234, 1318)\t5.0\n",
            "  (15234, 1570)\t5.0\n",
            "  (15234, 1917)\t5.0\n",
            "  (15234, 2002)\t4.0\n",
            "  (15234, 2021)\t2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION:\n",
        "\n",
        "1. `import pandas as pd`: Imports the Pandas library, providing data structures and functions to manipulate and analyze the dataset.\n",
        "\n",
        "2. `import numpy as np`: Imports the NumPy library, used for numerical operations, array handling, and mathematical functions in Python.\n",
        "\n",
        "3. `from scipy.sparse import csr_matrix`: Imports the Compressed Sparse Row (CSR) matrix from the SciPy library, a format suitable for handling sparse matrices efficiently.\n",
        "\n",
        "4. `ratings = pd.read_csv('/content/ratings.csv')`: Reads the CSV file named 'ratings.csv' located at the specified path into a Pandas DataFrame named `ratings`, containing user ratings data for movies. Each row likely represents a user's rating for a particular movie.\n",
        "\n",
        "5. `movies = pd.read_csv('/content/movies.csv')`: Reads the CSV file named 'movies.csv' from the given path into a Pandas DataFrame named `movies`, likely containing details about movies such as their titles, genres, or other information.\n",
        "\n",
        "6. `user_item_matrix = ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)`: Transforms the ratings DataFrame into a user-item matrix using the `pivot` function. It sets the 'userId' column as the index, 'movieId' column as columns, and 'rating' values as the cells in the matrix. Missing values are filled with 0 using `fillna(0)`.\n",
        "\n",
        "7. `user_item_matrix = csr_matrix(user_item_matrix.values.astype(float))`: Converts the user-item matrix into a sparse CSR matrix using SciPy's `csr_matrix`. This conversion is beneficial for handling large matrices with a substantial number of zero entries efficiently. It converts the matrix values to float type before creating the CSR matrix.\n",
        "\n",
        "8. `print(user_item_matrix)`: Outputs the resulting sparse CSR matrix to the console, enabling inspection of the generated matrix structure and content.\n",
        "\n",
        "In summary, the code snippet loads user ratings and movie data from CSV files, constructs a user-item matrix from the ratings, and converts it into a sparse CSR matrix, which is a suitable format for efficient handling of large matrices with many zero values. The final output displays the created sparse matrix."
      ],
      "metadata": {
        "id": "IyTZgKVV7L-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: SVD for Dimensionality Reduction\n",
        "\n",
        "Apply SVD to decompose the user-item matrix into three matrices: U, Σ, and V.\n",
        "Determine the optimal number of dimensions (rank) for dimensionality reduction using eigenvalues.\n",
        "Implement SVD to factorize the user-item matrix into three matrices: U, Σ, and V^T.\n",
        "Select the number of latent factors for the approximation.\n",
        "Reconstruct the user-item matrix with the reduced number of latent factors."
      ],
      "metadata": {
        "id": "b35HTyfKIOXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# Perform SVD\n",
        "U, Sigma, Vt = svds(user_item_matrix, k=50)\n",
        "# Perform SVD to obtain the predicted user-item matrix\n",
        "predicted_user_item_matrix = np.dot(np.dot(U, np.diag(Sigma)), Vt)\n",
        "print(predicted_user_item_matrix)\n",
        "\n",
        "# Determine the optimal rank (number of dimensions)\n",
        "eigenvalues = Sigma**2\n",
        "total_variance = sum(eigenvalues)\n",
        "explained_variance = eigenvalues / total_variance\n"
      ],
      "metadata": {
        "id": "cNkw6FySKbyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef5b20da-627c-44d3-eda2-3fb4fea4d5ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8.55596716e-01 -8.20716528e-02 -6.91274696e-02 ...  3.45595254e-04\n",
            "   3.30525617e-03  4.89172737e-03]\n",
            " [ 4.31670802e+00  5.98249524e-01  5.34098526e-02 ...  8.60760689e-05\n",
            "  -6.23751757e-03  5.03210455e-03]\n",
            " [ 1.25987037e+00  5.20406889e-01 -3.06507005e-01 ... -4.95613590e-03\n",
            "   8.30566022e-03 -7.11470588e-04]\n",
            " ...\n",
            " [ 9.22490649e-02  2.53577039e-02 -2.40184462e-03 ... -7.23358455e-04\n",
            "  -1.15936823e-03 -1.91951612e-03]\n",
            " [ 7.02445787e-01  2.08744490e-01  4.05626746e-03 ...  2.28384056e-03\n",
            "   3.01104465e-03  7.76880286e-04]\n",
            " [ 2.05587673e-01  1.07866400e-01  2.07639863e-02 ... -3.99134832e-04\n",
            "  -7.29403608e-04 -9.20273996e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `predicted_user_item_matrix` is calculated using matrix factorization techniques, specifically Singular Value Decomposition (SVD), as indicated in your code. Here's a detailed explanation of how it is computed:\n",
        "\n",
        "1. **Load and Prepare Data**:\n",
        "   - You start with user-item interaction data, often represented as a user-item matrix. In this case, you have a matrix `user_item_matrix` where rows represent users, columns represent items (movies), and the cells of the matrix contain user ratings for items. Rows correspond to users, and columns correspond to movies, with the matrix populated with user ratings.\n",
        "\n",
        "2. **SVD (Singular Value Decomposition)**:\n",
        "   - Singular Value Decomposition is a matrix factorization technique that breaks down the user-item matrix into three matrices: U, Σ (Sigma), and Vt (V transpose).\n",
        "\n",
        "   - U (user-feature matrix): Represents users in a lower-dimensional feature space.\n",
        "   - Σ (Sigma): A diagonal matrix representing singular values that quantifies the importance of the features.\n",
        "   - Vt (item-feature matrix): Represents items (movies) in the same lower-dimensional feature space as users.\n",
        "\n",
        "3. **Dimension Reduction**:\n",
        "   - To approximate the original user-item matrix, you typically reduce the dimensionality by keeping only the top-k singular values (where k is a hyperparameter you specify). This dimension reduction is achieved by truncating the U, Σ, and Vt matrices to retain only the top-k columns (features).\n",
        "\n",
        "   - The truncated matrices U, Σ, and Vt are used to construct an approximation of the original user-item matrix. The approximation is performed by multiplying U, Σ, and Vt back together.\n",
        "\n",
        "4. **Calculate Predictions**:\n",
        "   - The predicted user-item matrix is obtained by multiplying the truncated U, Σ, and Vt matrices.\n",
        "\n",
        "   ```python\n",
        "   predicted_user_item_matrix = U.dot(np.diag(Sigma)).dot(Vt)\n",
        "   ```\n",
        "\n",
        "   - This matrix represents predicted ratings for all users and items, with higher values indicating higher predicted ratings. It captures the underlying patterns and latent factors that influence user-item interactions.\n",
        "\n",
        "5. **Recommendation**:\n",
        "   - Once you have the `predicted_user_item_matrix`, you can use it to make movie recommendations for specific users. The matrix contains predicted ratings for all users and items, and you can retrieve the predicted ratings for a particular user and recommend items (movies) with the highest predicted ratings that the user hasn't yet rated.\n",
        "\n",
        "The SVD-based matrix factorization is a technique used in collaborative filtering to capture latent factors and make personalized recommendations. It is an essential component of recommendation systems, allowing you to estimate user preferences for items even when they haven't provided explicit ratings for those items."
      ],
      "metadata": {
        "id": "In5watiV23oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_variance)\n",
        "print(explained_variance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlyDYvFn7XWg",
        "outputId": "57ad07eb-0de3-4bf8-db78-a10da8deaa3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3036549.382456928\n",
            "[0.00426407 0.00436075 0.00439401 0.00448272 0.00451663 0.0046053\n",
            " 0.00465515 0.00469607 0.00475794 0.00479821 0.00485032 0.00503472\n",
            " 0.00508978 0.00515521 0.00518007 0.00528557 0.00547133 0.0056057\n",
            " 0.00579091 0.00582543 0.00599609 0.00614039 0.00617171 0.00641453\n",
            " 0.00642774 0.00669889 0.00683482 0.00695192 0.00758977 0.00799945\n",
            " 0.00815825 0.00822372 0.00876615 0.00949221 0.00998656 0.01032519\n",
            " 0.01168732 0.01224173 0.0131383  0.01357863 0.01478144 0.01740237\n",
            " 0.01819539 0.0258233  0.02785997 0.03079097 0.04459306 0.04932218\n",
            " 0.08895678 0.41063128]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Clustering Movies\n",
        "\n",
        "Cluster movies based on their low-dimensional representations (U matrix)."
      ],
      "metadata": {
        "id": "hX05jBlhIUwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "n_clusters = 5  # Choose the number of clusters\n",
        "n_init_value = 10  # Set the number of initializations (you can adjust this value)\n",
        "\n",
        "#kmeans = KMeans(n_clusters=n_clusters, n_init=n_init_value)\n",
        "#movie_clusters = kmeans.fit_predict(U)\n",
        "# Encode movie genres into binary features\n",
        "genres = movies['genres'].str.get_dummies('|')\n",
        "\n",
        "# Perform KMeans clustering based on genre\n",
        "\n",
        "kmeans = KMeans(n_clusters=n_clusters, n_init=n_init_value)\n",
        "genre_clusters = kmeans.fit_predict(genres)"
      ],
      "metadata": {
        "id": "rQcOafLAHafu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION:\n",
        "1. `from sklearn.cluster import KMeans`: This line imports the KMeans clustering algorithm from the scikit-learn library, which is a popular Python library for machine learning and data analysis. K-Means is an unsupervised machine learning algorithm used for clustering, which aims to partition data into groups, or clusters, based on similarity.\n",
        "\n",
        "2. `n_clusters = 5`: Here, you set the number of clusters (k) to 5. K-Means requires you to specify the number of clusters you want to create, which is a hyperparameter. In this case, you've chosen to create 5 clusters for the movies.\n",
        "\n",
        "3. `n_init_value = 10`: This line sets the number of times the K-Means algorithm will be initialized with different centroid seeds. The algorithm can converge to different solutions depending on the initial seed, so it's common to run it multiple times and select the best result. You've chosen to run it 10 times with different initializations.\n",
        "\n",
        "4. `genres = movies['genres'].str.get_dummies('|')`: This line encodes the movie genres into binary features using one-hot encoding. The 'genres' column in the 'movies' DataFrame contains a list of genres for each movie, separated by '|'. `get_dummies` is used to create binary columns for each unique genre, and a 1 is placed in the corresponding genre column if the movie belongs to that genre, otherwise, it's 0.\n",
        "\n",
        "5. `kmeans = KMeans(n_clusters=n_clusters, n_init=n_init_value)`: Here, you initialize the K-Means clustering algorithm with the specified number of clusters (5) and the number of initializations (10). This creates a K-Means estimator object that can be used for clustering.\n",
        "\n",
        "6. `genre_clusters = kmeans.fit_predict(genres)`: This line fits the K-Means model to the binary genre features in the 'genres' DataFrame using the `fit_predict` method. It assigns each movie to one of the 5 clusters based on the similarity of their genre profiles. The `genre_clusters` variable contains the cluster assignments for each movie.\n",
        "\n",
        "K-Means clustering is an iterative algorithm that aims to minimize the sum of squared distances between data points and their assigned cluster centroids. It starts with initial random centroids and iteratively assigns data points to the nearest centroid and updates the centroids until convergence. The result is that each data point (in this case, movies) is assigned to one of the specified clusters based on the similarity of their features (in this case, genres).\n",
        "\n",
        "this code,  group movies into clusters based on the genres they belong to. After clustering, you can analyze movies within the same genre cluster and potentially make recommendations or draw insights about user preferences within each cluster."
      ],
      "metadata": {
        "id": "Qky54bPV6d-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Recommendation Generation\n",
        "\n",
        "Select a user for whom to make movie recommendations.\n",
        "Find movies the user has not rated.\n",
        "Recommend movies based on predicted ratings from the reconstructed matrix.\n",
        "\n",
        "Movie Recommendation System Based on User Preferences and Genre Clusters"
      ],
      "metadata": {
        "id": "yX1lGsTyH8Fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a user for whom to make movie recommendations\n",
        "user_id = 42  # Example user ID\n",
        "user_ratings = user_item_matrix[user_id, :]\n",
        "\n",
        "# Find movies the user has not rated\n",
        "unrated_movie_indices = np.where(user_ratings.toarray() == 0)[1]\n",
        "\n",
        "# Recommend movies based on predicted ratings from the reconstructed matrix\n",
        "user_recommendations = predicted_user_item_matrix[user_id, :]\n",
        "recommended_movie_indices = user_recommendations.argsort()[::-1]\n",
        "\n",
        "# Filter out movies that the user has already rated\n",
        "recommended_movie_indices = [movie_idx for movie_idx in recommended_movie_indices if movie_idx in unrated_movie_indices]\n",
        "#Filters out movies that the user has already rated. This ensures that only unrated movies are considered for recommendations.\n",
        "\n",
        "# Get the top N recommended movies (e.g., top 10)\n",
        "top_n_recommendations = recommended_movie_indices[:10]\n",
        "\n",
        "# Fetch movie details for the recommended movies\n",
        "recommended_movies = movies.loc[top_n_recommendations]\n",
        "\n",
        "# Print the recommended movies\n",
        "print(\"Recommended Movies for User\", user_id)\n",
        "print(recommended_movies[['title', 'genres']])\n"
      ],
      "metadata": {
        "id": "uJto3dDZz1hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7QGgaQf5qvtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION:\n",
        "\n",
        "1. `user_id = 42`: This line sets the user's ID to 42 as an example. You can replace this with the ID of the user for whom you want to make movie recommendations.\n",
        "\n",
        "2. `user_ratings = user_item_matrix[user_id, :]`: This line extracts the row corresponding to the user with ID 42 from the `user_item_matrix`. It retrieves all the ratings that this user has given to different movies, resulting in a row of ratings for all movies.\n",
        "\n",
        "3. `unrated_movie_indices = np.where(user_ratings.toarray() == 0)[1]`: It identifies the indices of movies that the user has not rated. The `toarray()` method is used to convert the user's ratings from a sparse matrix to a dense array, and then it checks for ratings equal to 0, indicating that the user has not rated those movies. The resulting `unrated_movie_indices` array contains the indices of the movies the user hasn't rated.\n",
        "\n",
        "4. `user_recommendations = predicted_user_item_matrix[user_id, :]`: This line fetches the row from the `predicted_user_item_matrix` that corresponds to the user with ID 42. This matrix contains predicted ratings for all users and items, and you are extracting the row representing this specific user.\n",
        "\n",
        "5. `recommended_movie_indices = user_recommendations.argsort()[::-1]`: It sorts the movie indices in descending order based on the predicted ratings. Movies with higher predicted ratings come first.\n",
        "\n",
        "6. `recommended_movie_indices = [movie_idx for movie_idx in recommended_movie_indices if movie_idx in unrated_movie_indices]`: This line filters out movies that the user has already rated by comparing the recommended movie indices to the list of unrated movie indices obtained earlier. This ensures that only unrated movies are considered for recommendations.\n",
        "\n",
        "7. `top_n_recommendations = recommended_movie_indices[:10]`: It selects the top N recommended movies. In this case, it's set to 10, meaning the code will recommend the top 10 movies based on predicted ratings.\n",
        "\n",
        "8. `recommended_movies = movies.loc[top_n_recommendations]`: This line fetches movie details (title and genres) for the top recommended movies. `top_n_recommendations` contains the indices of these movies, which are used to index the `movies` DataFrame and retrieve the corresponding movie details.\n",
        "\n",
        "9. `print(\"Recommended Movies for User\", user_id)`: It prints a message indicating for which user the recommendations are made, in this case, \"Recommended Movies for User 42.\"\n",
        "\n",
        "10. `print(recommended_movies[['title', 'genres']])`: Finally, it prints the titles and genres of the recommended movies for the user, providing the user with the top movie recommendations."
      ],
      "metadata": {
        "id": "8ZMLi-2Y54Xb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Evaluation using  Mean Squared Error (MSE)"
      ],
      "metadata": {
        "id": "RuefCmNH3Shv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Mean Squared Error (MSE) as a measure of accuracy\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Example user ID\n",
        "user_id = 42\n",
        "\n",
        "# Extract actual ratings for the user\n",
        "actual_ratings = user_item_matrix[user_id, :].toarray().flatten()\n",
        "\n",
        "# Extract predicted ratings for the user\n",
        "predicted_ratings = predicted_user_item_matrix[user_id, :]\n",
        "\n",
        "# Filter out movies that the user has already rated\n",
        "unrated_movie_indices = np.where(actual_ratings == 0)[0]\n",
        "predicted_ratings = predicted_ratings[unrated_movie_indices]\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(actual_ratings[unrated_movie_indices], predicted_ratings)\n",
        "print(mse)\n",
        "accuracy = 1 - mse\n",
        "\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oJ-GI8drd4a",
        "outputId": "4362b519-2842-4ff1-96ec-a16af04d191c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.020243753440425297\n",
            "Accuracy: 0.9797562465595747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION:\n",
        "We calculate the Mean Squared Error (MSE) by comparing the actual ratings of the unrated movies with the predicted ratings. MSE is a measure of how well the predicted ratings align with the actual ratings. A lower MSE indicates better accuracy.\n",
        "the MSE of 0.07 in your movie recommendation project suggests that, on average, your model's predicted ratings are reasonably close to the actual ratings.\n",
        "\n",
        "It calculates the Mean Squared Error (MSE) and accuracy for a user in a movie recommendation system. The user's actual ratings are compared to the predicted ratings generated by the recommendation model. The MSE is computed by taking the average of the squared differences between actual and predicted ratings for movies the user has not yet rated (ratings are 0 for unrated movies). The accuracy is then calculated as 1 minus the MSE, providing an intuitive metric where higher values indicate better accuracy. Numerically, the MSE is computed by finding the squared differences for each unrated movie, averaging them, and subtracting this value from 1 to get accuracy. This evaluation approach focuses on how well the model predicts user preferences for unrated movies, contributing to the overall assessment of the recommendation system's performance. The code emphasizes extracting actual and predicted ratings, filtering out rated movies, and computing the MSE and accuracy for a specific user.\n",
        "\n",
        "If your actual ratings for unrated movies are consistently 0, it means that the ground truth for those cases is known and set to 0. In the context of a recommendation system, it's not uncommon to have 0 represent unrated or missing values. In such a case, using Mean Squared Error (MSE) as a measure of accuracy is conceptually valid.\n",
        "\n",
        "The MSE calculation involves comparing the predicted ratings (generated by your recommendation system) with the actual ratings (which are 0 for unrated movies). The goal is to assess how well the model's predictions align with the known ratings, even if those ratings are 0."
      ],
      "metadata": {
        "id": "IYwQA-Kvzyvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "REFERENCES:\n",
        "\n",
        "1. Towards Data Science:\n",
        "2. Kaggle:\n",
        "3. MovieLens Dataset : 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users\n",
        "4.\"Recommender Systems Handbook\" by Francesco Ricci, Lior Rokach, and Bracha Shapira:\n",
        "5. \"Collaborative Filtering for Implicit Feedback Datasets\" by Yifan Hu, Yehuda Koren, and Chris Volinsky:\n",
        "6. \"Programming Collective Intelligence\" by O'Reilly Media:"
      ],
      "metadata": {
        "id": "kMSkbsx43pS_"
      }
    }
  ]
}